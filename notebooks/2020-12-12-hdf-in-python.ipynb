{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing HDF files in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF file structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDF files have a hierarchical structure that consists of a directory and a collection of data objects. Every data object has a pointer to the data object location and information on its datatype. Different HDF formats allow different types of data objects.<br>\n",
    "Related data objects can be grouped into datasets similarly to subdirectories to organize files within a computer directory. <br><br>\n",
    "While netCDF4 format is based on HDF5, HDF files usually have a much more complex structure. You can think of HDF as groups of datasets. Hence, when you are reading a HDF file you first retrieve the list of groups, then the list of datasets for a particular group. You can then access each dataset in a similar manner as a netCDF file.<br><br>\n",
    "HDF formats are the older HDF4 and the current HDF5, then there are HDF4-EOS and HDF5-EOS which are used by NASA.<br><br>\n",
    "Since the HDF files can be so complex and it might not be immediately obvious which format youre dealing with, it is useful to open them with a viewer before accessing them. HDFView is specific to HDF and freely available, you can also use panoply which also opens netCDF files and is already available on the VDI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few python modules that can read HDF data. Here's a list with links to the available documentation:\n",
    "+ [pyhdf](http://fhs.github.io/pyhdf/)- developed by NASA specifically for HDF-EOS data\n",
    "+ [h5py](https://docs.h5py.org/en/stable/) - for HDF5 files\n",
    "+ xarray - currently works only with HDF4 and HDF5 not with HDF-EOS \n",
    "+ [rasterio](https://rasterio.readthedocs.io/en/latest/) - reads all raster data, can be used on its own or in conjuction with xarray\n",
    "+ [pynio](https://www.pyngl.ucar.edu/NioFormats.shtml#HDF) - can read and write HDF data that uses the SDS (Scientific Data Set) interface but only read HDF Vdata, SWATH and GRID data groups in HDF-EOS. POINT data groups are ignored\n",
    "+ [pandas PyTables](https://pandas.pydata.org/docs/user_guide/io.html#hdf5-pytables) - limited to specific datasets structures that Pandas understands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import pyhdf\n",
    "import h5py\n",
    "import netCDF4\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While HDF4 has been replaced by HDF5 for most new satellite products. NASA still uses a modified version (HDF4-EOS) for the MODIS products. It might also be encountered when using older datasets.<br>\n",
    "The HDF4 format and library support the following eight basic objects:\n",
    " 1. Scientific dataset (SDS), a multidimensional array with dimension scales\n",
    " 2. 8-bit raster image (RIS8), a 2-dimensional array of 8-bit pixels\n",
    " 3. 24-bit raster image (RIS24), a 2-dimensional array of 24-bit pixels\n",
    " 4. General raster image (GR), a 2-dimensional array of multi-component pixels\n",
    " 5. 8-bit color lookup table (palette), a 256 by 3 array of 8-bit integers\n",
    " 6. Table (Vdata), a sequence of records\n",
    " 7. Annotation, a stream of text that can be attached to any object\n",
    " 8. VGroup, a structure for grouping objects <br><br>\n",
    " \n",
    "It is likely you will deal only with the first one but it's good to know that HDF4 allows different and more complex objects compared to HDF5. While some python module might be able to deal with a relative simple HDF4 file, more complex ones needs a module that can deal with the complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HDF4-EOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NASA adapted both HDF4 and HDF5 to contain additional geolocated data types (point, grid, swath) from the Earth Observing System (EOS). HDF4-EOS, the format adapted from HDF4, is the one currently used for MODIS data products.\n",
    "\n",
    ".(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDF4 format can be opened in python using any of the following modules:\n",
    "  + rasterio\n",
    "  + xarray\n",
    "  + pyhdf\n",
    "  + pynio another option which is better than pyhdf if you have datasets with same name in different groups \n",
    "which to choose depend on which operations you want to do on the data, if you want to access in the same way other file formats etc. In some cases they would be fully equivalent and then you can choose the one which is more familiar to you.\n",
    "https://www.pyngl.ucar.edu/NioFormats.shtml#HDF\n",
    "Pynio can read and write HDF data that uses the SDS (Scientific Data Set) interface but only read HDF Vdata and for SWATH and GRID data groups in HDF-EOS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start from rasterio which is a wrapper of gdal, so you can use rasterio to open any kind of raster data provided that the underlining gdal has been compiled to include that file format.\n",
    "MODIS data usually comes as HDF4 so I'm using some files we have in project ua8 as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trmm = '/g/data/ua8/Precipitation/TRMM/3B42/hdf/1998/3B42.19980101.00.7.HDF'\n",
    "# HDF4-EOS\n",
    "modis = '/g/data/ua8/tmp/hdf_data/MOD09GA.A2016189.h09v05.006.2016191073856.hdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you try to open the file using xarray.open_dataset() function it will fail because xarray doesn't recognise HDF4-EOS format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rio.open(modis) as dataset:\n",
    "    print(dataset)\n",
    "    hdf4_meta = dataset.meta\n",
    "    for name in dataset.subdatasets:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading all 500m 2 D grid variables from file\n",
    "modis_ds = rio.open(modis)\n",
    "# You need to loop over the sds, open them and read the data as a list of numpy arrays\n",
    "sds_list = []\n",
    "# while looping we can also access the sds metadata and store it in a  dictionary\n",
    "modis_meta = {}\n",
    "for sds in modis_ds.subdatasets:\n",
    "    # selecting all variables on 500m_2D grid\n",
    "    if 'Grid_500m_2D' in sds:\n",
    "        with rio.open(sds) as subd:       \n",
    "            sds_list.append(subd.read(1))\n",
    "            # using only variable name for meta dictionary key\n",
    "            key = sds.split(\":\")[-1]\n",
    "            modis_meta[key] = subd.profile\n",
    "# stack the list of arrays in one\n",
    "modis_data = np.stack(sds_list)\n",
    "print(modis_data.shape, \"\\n\")\n",
    "print(modis_meta['sur_refl_b01_1'])\n",
    "# Close the file\n",
    "trmm_ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember you can always use dir() to find out all the methods and attributes of a python object\n",
    "  >  print( dir( modis_ds ) )\n",
    "  \n",
    "will give you a list of all the operations you can do on the rasterio file object.<br>\n",
    "We could get the data but we can't access the information on the variables, ie. whihc bands corresponds to which variable. If you tried to open the same file with panoply or HDFview you will see that such information is available in the file itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could access the variable information with this file, but this is not always the case, if we try to read the trmm file instead, while we can get the data values the information on the variables is lost.<br>\n",
    "Let's see an example while using this time rasterio with xarray.<br>\n",
    "Starting from xarray version 16.3 a new function *xarray.open_rasterio()* which uses *rasterio* to open the files is provided. <br> \n",
    "NB. This function is still experimental so it might not work with all files or it might change functionality in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use rasterio to get the subdatasets names\n",
    "with rio.open(trmm) as trmm_ds:\n",
    "    sds = trmm_ds.subdatasets\n",
    "\n",
    "print(sds[0])\n",
    "trmm_xr = xr.open_rasterio(sds[0])\n",
    "trmm_xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load all the sub-datasets we need to use a loop, after saving the single arrays in alist we'll concatenate them along the 'band' dimension. <br>\n",
    "Again, we can't access the actual metadata that would help us working out what each band represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for s in sds:\n",
    "    data.append(xr.open_rasterio(s))\n",
    "trmm_xr = xr.concat(data, dim='band') \n",
    "trmm_xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively you could use gdal rather than rasterio to load the subdatasets.\n",
    "# Remember rasterio is a gdal wrapper!\n",
    "\n",
    "import gdal\n",
    "\n",
    "g = gdal.Open(trmm)\n",
    "subdatasets = g.GetSubDatasets()\n",
    "# To close the gdal file\n",
    "g = None\n",
    "\n",
    "subdatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rasterio can do the job with or without xarray but it's a bit clunky compared to pyhdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pyhdf.HDF.HDF(modis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyhdf.SD import SD, SDC\n",
    "mod = SD(modis, SDC.READ)\n",
    "print(dir(mod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for attr in mod.attributes():\n",
    "    print(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key,ds in mod.datasets().items():\n",
    "    print(f\"{key}:  {ds}\")\n",
    "print(type(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_obj = mod.select('sur_refl_b01_1') # select  a ds\n",
    "\n",
    "data = ds_obj.get() # get ds data\n",
    "print(data)\n",
    "# get attributes\n",
    "print(ds_obj.attributes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDF5\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDF5 files are organized in a hierarchical structure, with two primary structures: groups and datasets.\n",
    "\n",
    "HDF5 group: a grouping structure containing instances of zero or more groups or datasets, together with supporting metadata.\n",
    "HDF5 dataset: a multidimensional array of data elements, together with supporting metadata.\n",
    "Working with groups and group members is similar in many ways to working with directories and files in UNIX. As with UNIX directories and files, objects in an HDF5 file are often described by giving their full (or absolute) path names.\n",
    "\n",
    "/ signifies the root group.\n",
    "/foo signifies a member of the root group called foo.\n",
    "/foo/zoo signifies a member of the group foo, which in turn is a member of the root group.\n",
    "Any HDF5 group or dataset may have an associated attribute list. An HDF5 attribute is a user-defined HDF5 structure that provides extra information about an HDF5 object. Attributes are described in more detail below.\n",
    "HDF5 Groups\n",
    "\n",
    "An HDF5 group is a structure containing zero or more HDF5 objects. A group has two parts:\n",
    "\n",
    "A group header, which contains a group name and a list of group attributes.\n",
    "A group symbol table, which is a list of the HDF5 objects that belong to the group.\n",
    "(Return to TOC)\n",
    "\n",
    "HDF5 Datasets\n",
    "\n",
    "A dataset is stored in a file in two parts: a header and a data array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDF5 example\n",
    "imerg = '/g/data/ua8/tmp/hdf_data/3B-MO.MS.MRG.3IMERG.20000601-S000000-E235959.06.V06B.HDF5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using xarray open_dataset(0  works with HDF5 file, you need though to specify the *h5netcdf* engine.<br>\n",
    "Let's see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(imerg, engine='h5netcdf')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xarray opened the file and can read the global attributes, but there are no variables or dimensions visible yet!<br>\n",
    "This is because of the HDF structured format, the top level is a group and we need to tell xarray we're dealing with groups. To do so we need to pass the group name to open_dataset() <br>\n",
    "If you haven't checked the file structure beforehand with HDFView or panoply, you can always use one of the other modules to retrieve the group/s names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with rio.open(imerg) as f:\n",
    "    for sds in f.subdatasets:\n",
    "        print(sds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see now that the main group is *Grid* and we can pass this information to xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xr.open_dataset(imerg, engine='h5netcdf', group='Grid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a file with sub-groups you can access them by using a path-like string: <br>\n",
    "> xr.open_dataset(file_path, engine='h5netcdf', group=\"/Group1/subgroup1')\n",
    "\n",
    "In the example above you can use both \"Grid\" and \"/Grid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative approach is to use netCDF4.Dataset to open the file in diskless non-persistence mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = netCDF4.Dataset(imerg, diskless=True, persist=False)\n",
    "group = nc.groups.get('Grid')\n",
    "#print(ncf.groups)\n",
    "xds = xr.open_dataset(xr.backends.NetCDF4DataStore(group))\n",
    "xds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imerg_ds = rio.open(imerg)\n",
    "print(imerg_ds.meta)\n",
    "sds = imerg_ds.subdatasets\n",
    "for s in sds:\n",
    "    with rio.open(s) as subd:\n",
    "        print(subd.units)\n",
    "xr.open_rasterio(sds[0])\n",
    "print(len(sds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(imerg,'r')\n",
    "groups = [ x for x in f.keys() ]\n",
    "print(groups)\n",
    "gridMembers = [ x for x in f['Grid'] ]\n",
    "print(gridMembers)\n",
    "\n",
    "# Read the precipitation, latitude, and longitude data:\n",
    "\n",
    "precip = f['Grid/precipitation'][0][:][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDF5-EOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(precip))\n",
    "precip.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show you can do that but only with data that has right table / datset structure\n",
    "#store = pd.io.pytables.HDFStore(imerg, 'r')\n",
    "print(store.info())\n",
    "some = pd.read_hdf(store)\n",
    "some\n",
    "#store.close()\n",
    "\n",
    "#print(store.info())\n",
    "#for k in store.keys():\n",
    "#    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally some resources: \n",
    " + https://www.earthdatascience.org/courses/use-data-open-source-python/hierarchical-data-formats-hdf/open-MODIS-hdf4-files-python/\n",
    " + https://www.youtube.com/watch?v=xuWB_byi-6Q\n",
    " + https://disc.gsfc.nasa.gov/information/howto?title=How%20to%20Read%20IMERG%20Data%20Using%20Python\n",
    " + https://support.hdfgroup.org/HDF5/doc/H5.intro.html\n",
    " + https://portal.hdfgroup.org/display/support/Documentation\n",
    " + https://moonbooks.org/Articles/How-to-read-a-MODIS-HDF-file-using-python-/\n",
    " (1) This information was adapted from  1st reference\n",
    " + example of modis pre-rpocessesing with gdal: http://www.loicdutrieux.net/pyLandsat/modisPreProcess.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-20.10] *",
   "language": "python",
   "name": "conda-env-analysis3-20.10-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
