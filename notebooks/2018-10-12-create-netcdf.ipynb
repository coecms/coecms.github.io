{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to create NetCDF files\n",
    "====="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very basic introduction into NetCDF files and how to create them.\n",
    "\n",
    "This document describes how to **create** a NetCDF file in Fortran, and later on in Python. The methods described herein will **overwrite** any existing file with the same name. Opening existing NetCDF files, either for reading or for modifying/appending, is different.\n",
    "\n",
    "The exact way data is stored in NetCDF Format is not necessary to know, but what you need to know is that each file consists of a header, which contains the meta-data, and the actual data.\n",
    "\n",
    "Metadata is Data about Data. It tells us the dimensions and datatypes of the data, as well as arbitrary attributes.\n",
    "\n",
    "Since the header is at the beginning of the file, and can change its length when new data is added or removed, it is very advisable to first create the header before starting to write the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a NetCDF file in Fortran\n",
    "----\n",
    "\n",
    "### netcdf module\n",
    "\n",
    "While there is an old-style Fortran 77 NetCDF interface, I strongly recommend using the Fortran 90 module:\n",
    "\n",
    "```\n",
    "program create_netcdf\n",
    "    use netcdf\n",
    "    implicit none\n",
    "end program create_netcdf\n",
    "```\n",
    "\n",
    "This is the most basic structure. To compile this program, you need the `netcdf` library in the `LD_LIBRARY_PATH`, on `raijin` this can be easily achieved by running the `module load netcdf` command (or any of the different versions).\n",
    "\n",
    "Then you need to compile it with the compiler options `-lnetcdf -lnetcdff`:\n",
    "\n",
    "```\n",
    "$ module load intel-fc/2018.3.222 netcdf/4.6.1\n",
    "$ ifort -o create_netcdf -lnetcdf -lnetcdff create_netcdf.f90\n",
    "```\n",
    "\n",
    "### netcdf Fortran 90 API\n",
    "\n",
    "The full API can be found here: https://www.unidata.ucar.edu/software/netcdf/netcdf-4/newdocs/netcdf-f90.html, but it's 10 years old and pretty out-of-date.\n",
    "\n",
    "Better to use the C API here: https://www.unidata.ucar.edu/software/netcdf/docs/modules.html, always replacing the leading `nc_` with `nf90_`.\n",
    "\n",
    "But the simple version is: Every instruction is a call to a **function** staring with `nf90_`, which returns an integer value as a status. Status `0` (or `NF90_NOERR`) means that the call was successful.\n",
    "\n",
    "I strongly suggest writing a little `check` routine, like this:\n",
    "\n",
    "```\n",
    "subroutine check(status, operation)\n",
    "    use netcdf\n",
    "    implicit none\n",
    "    integer, intent(in) :: status\n",
    "    character(len=*), intent(in) :: operation\n",
    "    if (status == NF90_NOERR) return\n",
    "    print *, \"Error encountered during \", operation\n",
    "    print *, nf90_strerror(status)\n",
    "    STOP 1\n",
    "end subroutine check\n",
    "```\n",
    "\n",
    "Then, after every call to any `nf90_` routine, you can call this check to see what happened. If all went fine, the call returns immediately, but if there was an error, you get a human-readable error output. \n",
    "\n",
    "### create an empty file\n",
    "\n",
    "To create a file, we need a file handle, an integer variable, by convention `ncid`, which, similar to the `unit` of `read` and `write` commands, references the file we created:\n",
    "\n",
    "```\n",
    "program create_netcdf\n",
    "    use netcdf\n",
    "    implicit none\n",
    "    integer :: status, ncid\n",
    "\n",
    "    status = nf90_create('data.nc', NF90_NETCDF4, ncid)\n",
    "    call check(status, 'open')\n",
    "    \n",
    "    status = nf90_close(ncid)\n",
    "    call check(status, 'close')\n",
    "  \n",
    "contains\n",
    "\n",
    "    subroutine check(status, operation)\n",
    "        ....\n",
    "    end subroutine check\n",
    "end program create_netcdf\n",
    "```\n",
    "\n",
    "The `NF90_HDF5` tells the NetCDF library which type of NetCDF file to create. This is the most recent version.\n",
    "\n",
    "*For the rest of the documentation I will no longer write the calls to `check`, please assume to do that after every call to any `nf90_` function*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a very basic header\n",
    "\n",
    "I now assume that I want to store a 2-d field: latitude by longitude. `ny` and `nx` are the number of gridpoints in latitude and longitude respectively. The field itself I simply call `field`, and `lat_array` and `lon_array` are arrays with the values for latitude and longitude.\n",
    "\n",
    "#### the dimensions\n",
    "\n",
    "First, we need the dimensions. Fundamentally, a dimension is just a name, and a length. For each dimension, we need an integer variable called a dimension id, or dimid. Assume we declared dimids for latitude and longitude called `dimid_lat` and `dimid_lon`:\n",
    "\n",
    "```\n",
    "    status = nf90_def_dim(ncid, 'longitude', nx, dimid_lon)\n",
    "    status = nf90_def_dim(ncid, 'latitude', ny, dimid_lat)\n",
    "```    \n",
    "\n",
    "We're only using fixed-length dimensions here, but if we wanted am unlimited dimension, we'd write `NF90_UNLIMITED` as the length of the dimensions (where we currently have `nx` and `ny`, respectively).\n",
    "\n",
    "#### the variables\n",
    "\n",
    "Next, we define 3 more integer variables, `varid_*`, one each for longitude and latitude (those will contain the actual values for the latitude and longitudes, and of course our field.\n",
    "\n",
    "```\n",
    "    status = nf90_def_var(ncid, 'longitude', NF90_FLOAT, [dimid_lon], varid_lon)\n",
    "    status = nf90_def_var(ncid, 'latitude', NF90_FLOAT, [dimid_lat], varid_lat)\n",
    "    status = nf90_def_var(ncid, 'field', NF90_FLOAT, [dimid_lon, dimid_lat], varid_field)\n",
    "```\n",
    "\n",
    "You can see that each variable needs a name, a type (in this case 32-bit floating points), an array of dimensions (referenced by the dimension IDs), and a new integer variable which references the variable itself.\n",
    "\n",
    "#### compression\n",
    "\n",
    "The field in our example is fairly small, but if it were larger, we would want to chunk and compress it.\n",
    "You can read about what chunking does here: https://www.unidata.ucar.edu/blogs/developer/entry/chunking_data_why_it_matters\n",
    "\n",
    "But here's how we do that in the Fortran Code: After we have defined a variable, we add this line:\n",
    "\n",
    "```\n",
    "    status = nf90_def_var_chunking(ncid, varid_field, NF90_CHUNKED, [10, 10])\n",
    "```\n",
    "\n",
    "`NF90_CHUNKED` -- as opposed to `NF90_CONTIGUOUS`, tells that the variable shall be chunked. We can also use an array to declare how the data should be chunked specifically.\n",
    "\n",
    "Once the data is declared as chunked, we can compress -- or deflate it:\n",
    "\n",
    "```\n",
    "    status = nf90_def_var_deflate(ncid, varid_field,          &\n",
    "                                  shuffle = 1,                &\n",
    "                                  deflate = 1,                &\n",
    "                                  deflate_level = 5  )\n",
    "```\n",
    "\n",
    "Here we have a noticeable point, both `shuffle` and `deflate` technically only need a boolean, but for reasons, you have to give them an integer: 0 for false, any other number for true.\n",
    "\n",
    "`shuffle` isn't all that important, but you might as well use it. `deflate` tells the netCDF library that the variable should be compressed. The compression level, between 0 and 9, can be set. 5 is usually a good compromise.\n",
    "\n",
    "#### the attributes\n",
    "\n",
    "Attributes can be attached to a variable, or to the file itself (global attribute). Common attributes are the units, long names, et cetera.\n",
    "\n",
    "```\n",
    "    status = nf90_put_att(ncid, NF90_GLOBAL, 'note', 'training file created with Fortran 90')\n",
    "    status = nf90_put_att(ncid, varid_lon, 'units', 'degree_east'\n",
    "    status = nf90_put_att(ncid, varid_lat, 'units', 'degree_north'\n",
    "    status = nf90_put_att(ncid, varid_field, '_FillValue', -2e8)\n",
    "```\n",
    "\n",
    "We can add any number of attributes to each variable, or even to the global file. They can be of any common type. For a list of attribute conventions, you can look here: http://cfconventions.org/\n",
    "\n",
    "#### end definition\n",
    "\n",
    "With NetCDF versions before version 4, we needed to tell the Fortran Module that we're finished with the header by calling `nf90_enddef`, but with NetCDF4 this is no longer necessary. Note that if you use older versions of NetCDF (declared in the `nf90_create` instruction above, you would have to make a call to `nf90_enddef` here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The actual data\n",
    "\n",
    "Let's create some data. I'm using implicit do loops to create even-spaced latitude and longitude arrays, and the `field` variable gets created in a do-loop:\n",
    "\n",
    "```\n",
    "    lat_array = [(ii * (360./nx), ii=0, nx-1)]\n",
    "    lon_array = [((jj * (180./(ny-1)) - 90.), jj=0, ny-1)]\n",
    "    do jj = 1, ny\n",
    "        do ii = 1, nx\n",
    "            field(ii, jj) = sin(lon_array(ii) * pi/180._real32) * &\n",
    "                cos(lat_array(jj) * pi/180._real32)\n",
    "        end do\n",
    "    end do\n",
    "```\n",
    "\n",
    "#### writing the data\n",
    "\n",
    "It is worth noting that the variable **definition** of the `field` has the dimensions in the same order as the actual 2-d array. This makes things very easy:\n",
    "\n",
    "```\n",
    "    status = nf90_put_var(ncid, varid_lon, lon_array)\n",
    "    status = nf90_put_var(ncid, varid_lat, lat_array)\n",
    "    status = nf90_put_var(ncid, varid_field, field)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "Looking at the output file, we notice something:\n",
    "\n",
    "```\n",
    "$ ncdump -h data.nc\n",
    "netcdf data {\n",
    "dimensions:\n",
    "\tlongitude = 200 ;\n",
    "\tlatitude = 101 ;\n",
    "variables:\n",
    "\tfloat longitude(longitude) ;\n",
    "\t\tlongitude:units = \"degree_east\" ;\n",
    "\tfloat latitude(latitude) ;\n",
    "\t\tlatitude:units = \"degree_north\" ;\n",
    "\tfloat field(latitude, longitude) ;\n",
    "\t\tfield:_FillValue = -2.e+08f ;\n",
    "\n",
    "// global attributes:\n",
    "\t\t:note = \"training file created with Fortran 90\" ;\n",
    "}\n",
    "```\n",
    "\n",
    "In Fortran, we always had the dimensions of `field` as (longitude, latitude), now it's the other way round.\n",
    "\n",
    "That's because Fortran stores multi-dimensional arrays the other way as almost all other programming languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python\n",
    "----\n",
    "\n",
    "In python, things are a lot easier. It can store the complete datastructure in memory, the output is then only a single line of code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import `xarray` and `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second: Create the latitude and longitude arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 200; ny = 101\n",
    "lon_array = np.linspace(0, 360, nx, endpoint=False, dtype=np.float32)\n",
    "lat_array = np.linspace(-90, 90, ny, endpoint=True, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third: Create the field, complete with values, dimensions, coordinates, and attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "field=xr.DataArray(\n",
    "    np.sin(lon_array[np.newaxis, :] * np.pi / 180.) * \n",
    "    np.cos(lat_array[:, np.newaxis] * np.pi / 180.),\n",
    "    dims = ['latitude', 'longitude'], \n",
    "    coords = {'longitude': lon_array, 'latitude': lat_array},\n",
    "    attrs = {'_FillValue':-2e8},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourth: The coordinate arrays don't have units yet, let's fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "field.latitude.attrs['units'] = 'degree_north'\n",
    "field.longitude.attrs['units'] = 'degree_east'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fifth: Create a Dataset containing all (in this case only one) field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.Dataset({'field':field}, attrs={'note':'training file created with xarray'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sixth: Use a single instruction to store all the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf('data.nc', format='NETCDF4', \n",
    "             encoding={'field':{\n",
    "                                'shuffle':True,\n",
    "                                'chunksizes':[101, 10],\n",
    "                                'zlib':True,\n",
    "                                'complevel':5\n",
    "            }})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.nc\r\n"
     ]
    }
   ],
   "source": [
    "!ls data.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netcdf data {\r\n",
      "dimensions:\r\n",
      "\tlongitude = 200 ;\r\n",
      "\tlatitude = 101 ;\r\n",
      "variables:\r\n",
      "\tfloat longitude(longitude) ;\r\n",
      "\t\tlongitude:_FillValue = NaNf ;\r\n",
      "\t\tlongitude:units = \"degree_east\" ;\r\n",
      "\t\tlongitude:_Storage = \"contiguous\" ;\r\n",
      "\t\tlongitude:_Endianness = \"little\" ;\r\n",
      "\tfloat latitude(latitude) ;\r\n",
      "\t\tlatitude:_FillValue = NaNf ;\r\n",
      "\t\tlatitude:units = \"degree_north\" ;\r\n",
      "\t\tlatitude:_Storage = \"contiguous\" ;\r\n",
      "\t\tlatitude:_Endianness = \"little\" ;\r\n",
      "\tfloat field(latitude, longitude) ;\r\n",
      "\t\tfield:_FillValue = -2.e+08f ;\r\n",
      "\t\tfield:_Storage = \"chunked\" ;\r\n",
      "\t\tfield:_ChunkSizes = 101, 10 ;\r\n",
      "\t\tfield:_DeflateLevel = 5 ;\r\n",
      "\t\tfield:_Shuffle = \"true\" ;\r\n",
      "\t\tfield:_Endianness = \"little\" ;\r\n",
      "\r\n",
      "// global attributes:\r\n",
      "\t\t:note = \"training file created with xarray\" ;\r\n",
      "\t\t:_NCProperties = \"version=1|netcdflibversion=4.6.1|hdf5libversion=1.10.1\" ;\r\n",
      "\t\t:_SuperblockVersion = 0 ;\r\n",
      "\t\t:_IsNetcdf4 = 1 ;\r\n",
      "\t\t:_Format = \"netCDF-4\" ;\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!ncdump -hs data.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
